Dataset: Cora():
===========================================================================================================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])
===========================================================================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True

Label Relation
============================================================
Gold Label Y: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
Shape: torch.Size([2708, 7])
Transpose of Y: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
Shape: torch.Size([7, 2708])
Gold A: tensor([[1., 0., 0.,  ..., 1., 1., 1.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 0.,  ..., 1., 1., 1.],
        [1., 0., 0.,  ..., 1., 1., 1.],
        [1., 0., 0.,  ..., 1., 1., 1.]])
Shape: torch.Size([2708, 2708])

Model GAT(
  (conv1): GATConv(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 0
===========================================================================================================
Run 0 Val. Acc. 0.824 Test Acc. 0.835
Finished Training 0 

A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 1
===========================================================================================================
Run 1 Val. Acc. 0.814 Test Acc. 0.831
Finished Training 1 

original data.num_edges 10556
new_edge tensor([[ 653,  176],
        [2534, 1043]], device='cuda:0') torch.Size([2, 2])
new_edge_homo tensor([[2534, 1043],
        [ 653,  176]], device='cuda:0') torch.Size([2, 2])
data.num_edges 10560
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10560])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10560])
data.num_edges 10560
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 2
===========================================================================================================
Run 2 Val. Acc. 0.818 Test Acc. 0.83
Finished Training 2 

original data.num_edges 10560
new_edge tensor([[2500,  337],
        [ 335,  686]], device='cuda:0') torch.Size([2, 2])
new_edge_homo tensor([[ 335,  686],
        [2500,  337]], device='cuda:0') torch.Size([2, 2])
data.num_edges 10564
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10564])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10564])
data.num_edges 10564
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 3
===========================================================================================================
Run 3 Val. Acc. 0.824 Test Acc. 0.826
Finished Training 3 

original data.num_edges 10564
new_edge tensor([[ 307,  149, 1658,  700, 2127, 1787],
        [1149, 2696,  656, 2540,  878, 1631]], device='cuda:0') torch.Size([2, 6])
new_edge_homo tensor([[1149, 2696,  656, 2540,  878, 1631],
        [ 307,  149, 1658,  700, 2127, 1787]], device='cuda:0') torch.Size([2, 6])
data.num_edges 10576
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10576])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10576])
data.num_edges 10576
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 4
===========================================================================================================
Run 4 Val. Acc. 0.81 Test Acc. 0.828
Finished Training 4 

original data.num_edges 10576
new_edge tensor([[1990,  327,  706],
        [1126, 2372,  385]], device='cuda:0') torch.Size([2, 3])
new_edge_homo tensor([[1126, 2372,  385],
        [1990,  327,  706]], device='cuda:0') torch.Size([2, 3])
data.num_edges 10582
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10582])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10582])
data.num_edges 10582
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 5
===========================================================================================================
Run 5 Val. Acc. 0.818 Test Acc. 0.828
Finished Training 5 

original data.num_edges 10582
new_edge tensor([[2234, 2408,  870],
        [1439,  454, 2323]], device='cuda:0') torch.Size([2, 3])
new_edge_homo tensor([[1439,  454, 2323],
        [2234, 2408,  870]], device='cuda:0') torch.Size([2, 3])
data.num_edges 10588
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10588])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10588])
data.num_edges 10588
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Task Loss + Link Prediction Loss
Dataset split is the public fixed split
Val. Acc.: 0.8168 +/- 0.0046647615158762114
Test. Acc.: 0.829 +/- 0.002
Vals Accs:  [0.814 0.818 0.824 0.81  0.818]
Test Accs [0.831 0.83  0.826 0.828 0.828]
