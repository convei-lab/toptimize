Dataset: Cora():
===========================================================================================================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])
===========================================================================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True

Label Relation
============================================================
Gold Label Y: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 1., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
Shape: torch.Size([2708, 7])
Transpose of Y: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
Shape: torch.Size([7, 2708])
Gold A: tensor([[1., 0., 0.,  ..., 1., 1., 1.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 0.,  ..., 1., 1., 1.],
        [1., 0., 0.,  ..., 1., 1., 1.],
        [1., 0., 0.,  ..., 1., 1., 1.]])
Shape: torch.Size([2708, 2708])

Model GAT(
  (conv1): GATConv(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 0
===========================================================================================================
Run 0 Val. Acc. 0.824 Test Acc. 0.835
Finished Training 0 

A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 1
===========================================================================================================
Run 1 Val. Acc. 0.838 Test Acc. 0.834
Finished Training 1 

original data.num_edges 10556
new_edge tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
new_edge_homo tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
data.num_edges 10556
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10556])
data.num_edges 10556
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 2
===========================================================================================================
Run 2 Val. Acc. 0.842 Test Acc. 0.839
Finished Training 2 

original data.num_edges 10556
new_edge tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
new_edge_homo tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
data.num_edges 10556
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10556])
data.num_edges 10556
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 3
===========================================================================================================
Run 3 Val. Acc. 0.836 Test Acc. 0.833
Finished Training 3 

original data.num_edges 10556
new_edge tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
new_edge_homo tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
data.num_edges 10556
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10556])
data.num_edges 10556
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 4
===========================================================================================================
Run 4 Val. Acc. 0.838 Test Acc. 0.85
Finished Training 4 

original data.num_edges 10556
new_edge tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
new_edge_homo tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
data.num_edges 10556
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10556])
data.num_edges 10556
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Model GAT(
  (conv1): GAT4ConvSIGIR(1433, 8, heads=8)
  (conv2): GATConv(64, 7, heads=1)
)
Optimizer Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0005

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
Start Training 5
===========================================================================================================
Run 5 Val. Acc. 0.836 Test Acc. 0.836
Finished Training 5 

original data.num_edges 10556
new_edge tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
new_edge_homo tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
data.num_edges 10556
dense_adj tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
dense_adj (norm) tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.],
        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0') torch.Size([2708, 2708])
edge_index tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],
        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])
edge_weight tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0') torch.Size([10556])
data.num_edges 10556
A tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        [0., 1., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 1.],
        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0') torch.Size([2708, 2708])
Task Loss + Link Prediction Loss
Dataset split is the public fixed split
Val. Acc.: 0.8380000000000001 +/- 0.002190890230020666
Test. Acc.: 0.838 +/- 0.006
Vals Accs:  [0.838 0.842 0.836 0.838 0.836]
Test Accs [0.834 0.839 0.833 0.85  0.836]
